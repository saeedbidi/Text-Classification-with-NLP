{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Download the Reuters dataset from NLTK\n",
    "nltk.download('reuters')\n",
    "\n",
    "# Get all possible categories in the Reuters corpus\n",
    "all_categories = reuters.categories()\n",
    "\n",
    "# Print the list of categories\n",
    "print(\"All Possible Categories:\")\n",
    "print(all_categories)\n",
    "\n",
    "# Load a subset of the Reuters dataset\n",
    "categories = ['earn', 'acq', 'nat-gas']\n",
    "documents = [(reuters.raw(fileid), category)\n",
    "             for category in categories\n",
    "             for fileid in reuters.fileids(category)[:50]]  # Limit to 50 documents for simplicity\n",
    "\n",
    "# Shuffle the documents\n",
    "import random\n",
    "random.shuffle(documents)\n",
    "\n",
    "# Separate features (text) and labels (earn/acq)\n",
    "X = [document for document, label in documents]\n",
    "y = [label for document, label in documents]\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Multinomial Naive Bayes classifier with parameter tuning\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_param_grid = {'alpha': [0.1, 0.5, 1.0, 1.5, 2.0]}\n",
    "nb_grid_search = GridSearchCV(nb_classifier, nb_param_grid, cv=5)\n",
    "nb_grid_search.fit(X_vec, y)\n",
    "best_nb_classifier = nb_grid_search.best_estimator_\n",
    "\n",
    "# Train a Logistic Regression classifier with parameter tuning\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_param_grid = {'C': [0.1, 0.5, 1.0, 1.5, 2.0], 'max_iter': [100, 200, 300]}\n",
    "lr_grid_search = GridSearchCV(lr_classifier, lr_param_grid, cv=5)\n",
    "lr_grid_search.fit(X_vec, y)\n",
    "best_lr_classifier = lr_grid_search.best_estimator_\n",
    "\n",
    "# Train a Random Forest classifier with parameter tuning\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_param_grid = {'n_estimators': [50, 100, 150], 'max_depth': [None, 10, 20]}\n",
    "rf_grid_search = GridSearchCV(rf_classifier, rf_param_grid, cv=5)\n",
    "rf_grid_search.fit(X_vec, y)\n",
    "best_rf_classifier = rf_grid_search.best_estimator_\n",
    "\n",
    "# Test the classifiers\n",
    "classifiers = {'Multinomial Naive Bayes': best_nb_classifier,\n",
    "               'Logistic Regression': best_lr_classifier,\n",
    "               'Random Forest': best_rf_classifier}\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    predicted_labels = classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the accuracy\n",
    "    accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    print(f\"\\n{name} Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "    # Display classification report\n",
    "    print(f\"Classification Report for {name}:\\n\", classification_report(y_test, predicted_labels))\n",
    "\n",
    "# Sample news articles\n",
    "earnings_article = \"\"\"\n",
    "TechCorp announced record-breaking earnings in the third quarter of this year. The company's profits soared by 20%, driven by strong sales of their latest products.\n",
    "\"\"\"\n",
    "\n",
    "acquisitions_article = \"\"\"\n",
    "In a major move, Company XYZ has acquired ABC Corp, marking a significant consolidation in the industry. The acquisition is expected to strengthen their market presence and drive future growth.\n",
    "\"\"\"\n",
    "test_article = '''UK is importing'''\n",
    "sugar_article = \"\"\"\n",
    "Natural gas price goes up.\n",
    "\"\"\"\n",
    "# Combine the articles into a list\n",
    "news_articles = [earnings_article, acquisitions_article, sugar_article, test_article]\n",
    "\n",
    "# Vectorize the text data\n",
    "X_test_vec = vectorizer.transform(news_articles)\n",
    "\n",
    "# Predict the labels using the tuned classifiers\n",
    "for name, classifier in classifiers.items():\n",
    "    predicted_labels = classifier.predict(X_test_vec)\n",
    "\n",
    "    # Display the predicted labels for each article\n",
    "    print(f\"\\n{name} Predicted Labels:\")\n",
    "    for article, label in zip(news_articles, predicted_labels):\n",
    "        print(f\"Article:\\n{article}\\nPredicted Label: {label}\\n{'='*50}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
